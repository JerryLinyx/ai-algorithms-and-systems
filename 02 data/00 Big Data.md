## 1. Hadoop：大数据的开山鼻祖

Hadoop 是大数据生态的基石。它解决的是最核心的问题：**如何廉价地存储海量数据**以及**如何在大规模集群上运行计算**。
- **核心组件：**
    - **HDFS (存储)：** 分布式文件系统，把文件切碎存放在成百上千台服务器上。
    - **MapReduce (计算)：** 第一代计算引擎，采用“分而治之”的思想，但因为频繁读写硬盘，速度较慢。
    - **YARN (资源管理)：** 相当于数据中心的操作系统，负责分配 CPU 和内存。
- **适用场景：** 离线批处理、大规模数据备份、对时间不敏感的长周期任务。

---

## 2. Spark：全能的“内存计算”大师

Spark 的出现是为了解决 Hadoop MapReduce 太慢的问题。它最大的创新是 **RDD（弹性分布式数据集）**，尽可能将数据放在**内存**中计算。
- **核心特点：**
    - **快：** 官方称其在内存中比 MapReduce 快 100 倍。
    - **全栈：** 一个引擎搞定一切（Spark SQL、Spark Streaming、MLlib 机器学习、GraphX 图计算）。
    - **微批处理 (Micro-batch)：** Spark Streaming 其实是将流数据切成一小段一小段的“微型批处理”来执行。
- **适用场景：** 迭代计算（机器学习）、交互式查询、复杂的 ETL 处理。

---

## 3. Flink：真正的流处理王者

Flink 是目前大数据领域最炙手可热的技术。与 Spark 不同，Flink 天生就是为了**流处理（Stream Processing）**而设计的，它认为“一切皆流”。
- **核心特点：**
    - **极低延迟：** 能够实现毫秒级的实时响应。
    - **真正的流处理：** 数据来一条处理一条，而不是攒一小堆再处理。
    - **Exactly-once 语义：** 哪怕系统崩溃，也能保证数据不丢不重，这在金融支付领域极其重要。
- **适用场景：** 实时大屏展示、反欺诈实时监测、实时推荐系统。

---